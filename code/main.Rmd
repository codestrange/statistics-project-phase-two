---
title: "Proyecto de Estadística"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

## Regresion y ACP

Primero vamos a importar las bibliotecas necesarias, leer la base de datos,
filtrarla por los equipos de la fase de grupos de la UEFA Champions League,
cambiarle el nombre a las variables para reducirle el tamaño (para que sea
más comodo trabajar con ellas) y por último veremos una descripción general
de los datos utilizando la función `skim` de la biblioteca `skimr`.

```{r}
library(corrplot)
library(skimr)
library(lmtest)
library(rpart)
library(nortest)

db <- read.csv(file = 'database.csv')

uefa_teams = c(
    'AtlÃ©tico Madrid',
    'Juventus',
    'Olympiacos CFP',
    'MalmÃ¶ FF',
    'Real Madrid',
    'FC Basel 1893',
    'Liverpool',
    'AS Monaco',
    'Bayer 04 Leverkusen',
    'Zenit St. Petersburg',
    'SL Benfica',
    'Borussia Dortmund',
    'Arsenal',
    'RSC Anderlecht',
    'Galatasaray SK',
    'FC Bayern MÃ¼nchen',
    'Manchester City',
    'Roma',
    'PFC CSKA Moscow',
    'FC Barcelona',
    'Paris Saint-Germain',
    'Ajax',
    'Chelsea',
    'FC Schalke 04',
    'Sporting CP',
    'FC Porto',
    'Shakhtar Donetsk',
    'Athletic Club de Bilbao'
)

uefa_db <- data.frame(db[db$club %in% uefa_teams, ])

short_db <- data.frame(
    uefa_db$overall,
    uefa_db$potential,
    uefa_db$attacking_finishing,
    uefa_db$attacking_short_passing,
    uefa_db$skill_ball_control,
    uefa_db$skill_fk_accuracy,
    uefa_db$skill_long_passing,
    uefa_db$movement_agility,
    uefa_db$movement_balance,
    uefa_db$movement_sprint_speed,
    uefa_db$power_shot_power,
    uefa_db$power_stamina,
    uefa_db$power_long_shots,
    uefa_db$mentality_interceptions,
    uefa_db$mentality_vision,
    uefa_db$defending_marking,
    uefa_db$defending_sliding_tackle
)

colnames(short_db) <- c(
    "overall",
    "potential",
    "attacking_finishing",
    "attacking_short_passing",
    "skill_ball_control",
    "skill_fk_accuracy",
    "skill_long_passing",
    "movement_agility",
    "movement_balance",
    "movement_sprint_speed",
    "power_shot_power",
    "power_stamina",
    "power_long_shots",
    "mentality_interceptions",
    "mentality_vision",
    "defending_marking",
    "defending_sliding_tackle"
)

data_sum <- skim(short_db)
data_sum
```

Se puede observar que la media de las habilidades de los jugadores es baja
incluso para los mejores equipos de las mejores ligas de Futbol. Analizando
los cuartiles podemos percatarnos que el 75% de los jugadores están por debajo
de 80 puntos (exceptuando el caso del `potential` que alvanza 83) lo cual
quiere decir que los jugadores considerados tops corresponden solo a un 15%.

### Analisis de correlacion de las variables seleccionadas

```{r}
cor_short_db <- cor(short_db)
corrplot(cor_short_db, method = "number", number.digits=1)
```

Se puede observar una alta correlación entre las variables, por lo que no sería
correcto aplicar una regresión lineal, por lo tanto aplicaremos una reducción
de dimensiones para obtener nuevas variables que sean independientes entre si
y que sean dependientes de una variable respuesta que elijamos.

### Reducción de dimensiones

Seleccionaremos la variable `overall` como variable respuesta. Por lo que la
sacaremos de las variables que vayamos a aplicarle el ACP.

```{r}
idx_var_answer <- 1
acp <- prcomp(short_db[-c(idx_var_answer)], scale. = TRUE)
plot(acp)
summary(acp)
```

Aplicando el criterio de Kaiser, podemos quedarnos con las primeras tres
variables. Pasaremos a crear una matriz con la variable respuesta junta las
tres variables nuevas seleccionadas generadas por el ACP y analizar sus
correlaciones.

```{r}
reg_data <-
  as.data.frame(cbind(scale(short_db[c(idx_var_answer)]), acp$x[, 1:3]))
cor_reg_data <- cor(reg_data)
corrplot(cor_reg_data, method = "number")
pairs(reg_data)
```

Como podemos ver la variable respuesta escogida no tiene dependencia con las
variables nuevas seleccionadas generadas por el ACP, haciendo una analisis
similar iterando por todas las variables seleccionandolas como variable
respuesta en cada paso obtenemos que la variable `mentality_interceptions`
que tiene una mayor correlación con las tres variables nuevas seleccionadas
generadas por el ACP como se puede observar a continuación es una mejor
selección como variable respuesta.

```{r}
idx_var_answer <- 14
acp <- prcomp(short_db[-c(idx_var_answer)], scale. = TRUE)
plot(acp)
summary(acp)
reg_data <-
  as.data.frame(cbind(scale(short_db[c(idx_var_answer)]), acp$x[, 1:3]))
cor_reg_data <- cor(reg_data)
corrplot(cor_reg_data, method = "number")
pairs(reg_data)
```

### Analisis de las variables nuevas seleccionadas generadas por el ACP

```{r}
idx <- 3
acp_abs <- abs(acp$rotation[, idx])
rel_acp <- acp$rotation[acp_abs >= max(acp_abs) / 2, idx]
pos_acp <- data.frame(rel_acp[rel_acp >= 0])
neg_acp <- data.frame(rel_acp[rel_acp < 0])
pos_acp
neg_acp
```

### Regresión lineal multiple

```{r}
model <- lm("mentality_interceptions ~ .", data = reg_data)
summary(model)
```

### Analisis de los supuestos

```{r}
"Media de los Errores"
mean(model$residuals)

"Suma de los Errores"
sum(model$residuals)

dwtest(model)

shapiro.test(model$residuals)

hist(model$residuals)

qqnorm(model$residuals)
qqline(model$residuals)

plot(reg_data$mentality_interceptions,
     rstandard(model),
     ylab = "Residuos estandarizados",
     xlab = "Val. General")
abline(h = 0, lty = 2)

bptest(model)
```

Conclusion, hay independencia, No hay normalidad y hay homocedasticidad

## Anova ##

```{r}
MI = c(short_db$defending_sliding_tackle)
Fo = as.numeric(c(uefa_db$preferred_foot == 'Right'))
data_anova = data.frame(Fo, MI)
boxplot(MI ~ Fo, data=data_anova)
anova_model = aov(MI ~ Fo, data = data_anova)
summary(anova_model)
hist(anova_model$residuals)
plot(anova_model)
shapiro.test(anova_model$residuals)
bartlett.test(anova_model$residuals, data_anova$Fo)
dwtest(anova_model)
```

## Clusters ##

En el siguiente análisis utilizando clústeres se tomó como referencia los
resultados obtenidos del análisis de las componentes principales, en las
que según el críterio del porcentaje el resultado era dos componentes
principales y según el críterio de Kaiser el resultado era tres componentes
principales.

```{r}
clusters <- function(data, ks, colors, method = "euclidean") {
  d <- dist(data, method = method)
  fit <- hclust(d, method = "complete")
  
  # filename <-
    # paste("images/hier_cluster", "_", k, "_", method, ".png", sep = "")
  # png(filename = filename)
  plot(fit)
  i <- 1
  while (i <= length(ks)) {
    rect.hclust(fit, k = ks[i], border = colors[i])
    i <- i + 1
  }
  # dev.off()
}

data_clusters = as.data.frame(scale(short_db))

clusters(data_clusters, c(2, 3), c("red", "blue"))
```

Analizando el dendrograma se puede observar que tanto para dos como para tres
clústeres existe uno de los clústeres que tiene la mayoría de los datos, por
lo que se analizó aumentar la cantidad de clústeres a 4, 5, 6 y 7 para analizar
el comportamiento con estas cantidades.

```{r}
clusters(data_clusters, c(4, 5, 6, 7), c("red", "blue", "yellow", "green"))
```

Del análisis anterior se eligió 6 clústeres como medidor principal debido a
que con 4 y 5 clústeres permanecía una diferencia sustancial en cuanto a la
cantidad de datos en cada clúster, y con 7 clústeres no se observó una mejora
sobre a elección de 6 clústeres. Tomando en cuenta que se están segmentando
en grupos a jugadores de futbol según sus características, 6 grupos no es una
división exagerada, ya que los jugadores se pueden dividir por posiciones en
el campo, estilo, portero, defensas centrales, laterales, mediocampistas
defensivos, medio campistas ofencivos y delanteros. No quiere decir que el
análisis con 6 clústeres determine estos grupos, solamente se quisó ilustrar
que una clasificación en 6 grupos a los futbolistas no es una división extraña.

## K-Means ##

Se realizó un análisis utilizando el algoritmo de K-medias. Se utilizaron 6
particiones basándose en el resultado del análisis de los clústeres.

```{r}
k_means <- function(data, k) {
  km <- kmeans(data, k)
  
  print(km)
  
  # filename <- paste("images/kmeans_cluster", "_", k, ".png", sep = "")
  # png(filename = filename)
  plot(data, col = km$cluster)
  # dev.off()
}

k_means(data_clusters, 6)
```

Del análisis anterior se obtuvo que el porciento de similitud es del 69%
aproximadamente, lo cual es bastante bueno para la naturaleza de los datos
que se analizaron. La cantidad de elementos en cada partición fue de
94, 168, 207, 98, 122, 139 respectivamente.

## Árboles de Decisión

```{r}
d_tree <- function(data, var, depth) {
  n <- length(data[, 1])
  
  model <- paste(var, "~ .")
  
  sub <- sample(1:n, 2 * n / 3)
  
  diag.tree <-
    rpart( model, data = data[sub, ], cp = 0.01, maxdepth = depth)
  
  # summary(diag.tree)
  
  # filename <-
  #   paste("images/d_tree_cluster", "_", var, "_", depth, ".png", sep = "")
  # png(filename = filename)
  plot(diag.tree)
  text(diag.tree,
       use.n = TRUE,
       all = FALSE,
       pretty = 1,
       xpd = TRUE)
  # dev.off()
  
  # plotcp(diag.tree)
  # printcp(diag.tree)

  diag.pred <-
    predict(diag.tree, newdata = data[-sub, ], type = "vector")

  tb <- table(diag.pred, data[-sub, ][[var]])

  error.rpart <- 1 - (sum(diag(tb)) / sum(tb))
  print(tb)
  print(error.rpart)
}

d_tree(short_db, "overall", 3)
```

En un inicio, debido a que el modelo de regresión lineal no fue útil, ya que
se incumplieron sus supuestos, se decidió realzar un análisis utilizando
árboles de decisión, en primer árbol de decisión se realizó utilizando las
17 variables seleccionadas y como variable respuesta a overall, el resultado
se puede observar a continuación, pero el error es del 99% por lo que se
intento con un segundo árbol de decisión utilizando como variable respuesta
mentality_interceptions y como variables independientes a las componentes
principales, nuevamente el error fue alto, cercano al 98%.

```{r}
d_tree(reg_data, "mentality_interceptions", 3)
```
